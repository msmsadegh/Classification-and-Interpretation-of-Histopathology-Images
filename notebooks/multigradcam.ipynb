{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading all single models\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_addons as tfa\n",
    "modelv1b0 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv1b0best.h5')\n",
    "modelv1b1 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv1b1best.h5')\n",
    "modelv1b2 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv1b2best.h5')\n",
    "modelv1b3 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv1b3best.h5')\n",
    "modelv1b4 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv1b4best.h5')\n",
    "modelv2b0 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv2b0best.h5')\n",
    "modelv2b1 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv2b1best.h5')\n",
    "modelv2b2 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv2b2best.h5')\n",
    "modelv2b3 = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv2b3best.h5')\n",
    "modelv2bS = load_model('C:\\\\Users\\\\Administrator\\\\Desktop\\\\v1\\\\efficientnetv2bsbest.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1656991096569,
     "user": {
      "displayName": "mahdi azmoodeh",
      "userId": "07920559924737018455"
     },
     "user_tz": -270
    },
    "id": "tjX1caKCJZUT"
   },
   "outputs": [],
   "source": [
    "#grad-cam function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "def grad_cam(input_model, image, layer_name):\n",
    "    img_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    x = img_arr[tf.newaxis]\n",
    "    x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "\n",
    "    grad_model = tf.keras.models.Model([input_model.inputs], [input_model.get_layer(layer_name).output, input_model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(x)\n",
    "        class_idx = np.argmax(predictions[0])\n",
    "        loss = predictions[:, class_idx]\n",
    "\n",
    "\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "    gate_f = tf.cast(output > 0, 'float32')\n",
    "    gate_r = tf.cast(grads > 0, 'float32')\n",
    "\n",
    "    guided_grads = gate_f * gate_r * grads\n",
    "\n",
    "    weights = np.mean(guided_grads, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "    cam = cv2.resize(cam, (x.shape[1], x.shape[2]), cv2.INTER_LINEAR)\n",
    "\n",
    "    cam  = np.maximum(cam, 0)\n",
    "\n",
    "    heatmap = cam / cam.max()\n",
    "\n",
    "\n",
    "    jet_cam = cv2.applyColorMap(np.uint8(255.0*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    rgb_cam = np.float32(cv2.cvtColor(jet_cam, cv2.COLOR_BGR2RGB))\n",
    "    output_arr = cv2.addWeighted(src1=img_arr, alpha=0.7, src2=rgb_cam, beta=0.3, gamma=0)\n",
    "    output_image = tf.keras.preprocessing.image.array_to_img(output_arr)\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1656991096572,
     "user": {
      "displayName": "mahdi azmoodeh",
      "userId": "07920559924737018455"
     },
     "user_tz": -270
    },
    "id": "F0ad8N-SfHGB"
   },
   "outputs": [],
   "source": [
    "#function for merging images\n",
    "def merge_images(file1, file2,file3,file4,file5,file6,file7,file8,file9,file10):\n",
    "    image1 = file1\n",
    "    image2 = file2\n",
    "    image3 = file3\n",
    "    image4 = file4\n",
    "    image5 = file5\n",
    "    image6 = file6\n",
    "    image7 = file7\n",
    "    image8 = file8\n",
    "    image9 = file9\n",
    "    image10 = file10\n",
    "    \n",
    "    (width1, height1) = image1.size\n",
    "    (width2, height2) = image2.size\n",
    "    (width3, height3) = image3.size\n",
    "    (width4, height4) = image4.size\n",
    "    (width5, height5) = image5.size\n",
    "    (width6, height6) = image6.size\n",
    "    (width7, height7) = image7.size\n",
    "    (width8, height8) = image8.size\n",
    "    (width9, height9) = image9.size\n",
    "    (width10, height10) = image10.size\n",
    "    \n",
    "    result_width = max(width1 + width2 + width3 + width4 + width5,width6 + width7 + width8 + width9 + width10)\n",
    "    result_height = max(height1+20, height2+20, height3+20 , height4+20 , height5+20)+ max(height6+20, height7+20, height8+20 , height9+20 , height10+20) \n",
    "    v1=max(height1+20, height2+20, height3+20 , height4+20 , height5+20)\n",
    "    result = Image.new('RGB', (result_width, result_height))\n",
    "    \n",
    "    result.paste(im=image1, box=(0, 0))\n",
    "    result.paste(im=image2, box=(width1, 0))\n",
    "    result.paste(im=image3, box=(width1+width2, 0))\n",
    "    result.paste(im=image4, box=(width1+width2+width3, 0))\n",
    "    result.paste(im=image5, box=(width1+width2+width3+width4, 0))\n",
    "    \n",
    "    result.paste(im=image6, box=(0, v1))\n",
    "    result.paste(im=image7, box=(width6, v1))\n",
    "    result.paste(im=image8, box=(width6+width7, v1))\n",
    "    result.paste(im=image9, box=(width6+width7+width8, v1))\n",
    "    result.paste(im=image10, box=(width6+width7+width8+width9, v1))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 952828,
     "status": "ok",
     "timestamp": 1656992533512,
     "user": {
      "displayName": "mahdi azmoodeh",
      "userId": "07920559924737018455"
     },
     "user_tz": -270
    },
    "id": "7Bnj0v2a0ma1",
    "outputId": "79cd7050-d017-40d3-89e0-2acaf7d080ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000235C46E4310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000235CAE420D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#multigradcam for benign\n",
    "import os\n",
    "from PIL import Image \n",
    "import PIL\n",
    "from PIL import Image, ImageDraw  \n",
    "root_src = 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\1\\\\test\\\\benign'\n",
    "\n",
    "base_input_shapev1b0 = modelv1b0.input_shape[1:]\n",
    "base_input_shapev1b1 = modelv1b1.input_shape[1:]\n",
    "base_input_shapev1b2 = modelv1b2.input_shape[1:]\n",
    "base_input_shapev1b3 = modelv1b3.input_shape[1:]\n",
    "base_input_shapev1b4 = modelv1b4.input_shape[1:]\n",
    "base_input_shapev2b0 = modelv2b0.input_shape[1:]\n",
    "base_input_shapev2b1 = modelv2b1.input_shape[1:]\n",
    "base_input_shapev2b2 = modelv2b2.input_shape[1:]\n",
    "base_input_shapev2b3 = modelv2b3.input_shape[1:]\n",
    "base_input_shapev2bs = modelv2bS.input_shape[1:]\n",
    "\n",
    "layer_name = 'top_activation'\n",
    "files=[]\n",
    "files = os.listdir(root_src)\n",
    "for file in files:\n",
    "    #v1\n",
    "  img_path=os.path.join(root_src,file)\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b0[0], base_input_shapev1b0[1]))\n",
    "  camv1b0 = grad_cam(modelv1b0, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b0=modelv1b0.predict(x)\n",
    "  v1b0=v1b0[0][0]\n",
    "\n",
    "\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b1[0], base_input_shapev1b1[1]))\n",
    "  camv1b1 = grad_cam(modelv1b1, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b1=modelv1b1.predict(x)\n",
    "  v1b1=v1b1[0][0]\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b2[0], base_input_shapev1b2[1]))\n",
    "  camv1b2 = grad_cam(modelv1b2, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b2=modelv1b2.predict(x)\n",
    "  v1b2=v1b2[0][0]\n",
    "\n",
    "\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b3[0], base_input_shapev1b3[1]))\n",
    "  camv1b3 = grad_cam(modelv1b3, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b3=modelv1b3.predict(x)\n",
    "  v1b3=v1b3[0][0]\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b4[0], base_input_shapev1b4[1]))\n",
    "  camv1b4 = grad_cam(modelv1b4, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b4=modelv1b4.predict(x)\n",
    "  v1b4=v1b4[0][0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  #v2  \n",
    "  img_path=os.path.join(root_src,file)\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2b0[0], base_input_shapev2b0[1]))\n",
    "  camv2b0 = grad_cam(modelv2b0, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2b0=modelv2b0.predict(x)\n",
    "  v2b0=v2b0[0][0]\n",
    "\n",
    "\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2b1[0], base_input_shapev2b1[1]))\n",
    "  camv2b1 = grad_cam(modelv2b1, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2b1=modelv2b1.predict(x)\n",
    "  v2b1=v2b1[0][0]\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2b2[0], base_input_shapev2b2[1]))\n",
    "  camv2b2 = grad_cam(modelv2b2, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2b2=modelv2b2.predict(x)\n",
    "  v2b2=v2b2[0][0]\n",
    "\n",
    "\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2b3[0], base_input_shapev2b3[1]))\n",
    "  camv2b3 = grad_cam(modelv2b3, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2b3=modelv2b3.predict(x)\n",
    "  v2b3=v2b3[0][0]\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2bs[0], base_input_shapev2bs[1]))\n",
    "  camv2bs = grad_cam(modelv2bS, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2bs=modelv2bS.predict(x)\n",
    "  v2bs=v2bs[0][0]\n",
    "####\n",
    "\n",
    "\n",
    "  img_pathdes=os.path.join('C:\\\\Users\\\\Administrator\\\\Desktop\\\\multigradcam\\\\benign',file)\n",
    "  result=merge_images(camv1b0,camv1b1,camv1b2,camv1b3,camv1b4,camv2b0,camv2b1,camv2b2,camv2b3,camv2bs)\n",
    "  d1 = ImageDraw.Draw(result)\n",
    "  d1.text((5, 370), str(v1b0), fill=(255, 255, 255))\n",
    "  d1.text((229, 370), str(v1b1), fill=(255, 255, 255))\n",
    "  d1.text((469, 370), str(v1b2), fill=(255, 255, 255))\n",
    "  d1.text((729, 370), str(v1b3), fill=(255, 255, 255))\n",
    "  d1.text((1029, 390), str(v1b4), fill=(255, 255, 255))\n",
    "  v1bb=(v1b0+v1b1+v1b2+v1b3+v1b4)/5\n",
    "  d1.text((1100,380 ), str(v1bb), fill=(255, 255, 255))\n",
    "  \n",
    "    \n",
    "  d1.text((5, 770), str(v2b0), fill=(255, 255, 255))\n",
    "  d1.text((229, 770), str(v2b1), fill=(255, 255, 255))\n",
    "  d1.text((469, 770), str(v2b2), fill=(255, 255, 255))\n",
    "  d1.text((729, 770), str(v2b3), fill=(255, 255, 255))\n",
    "  d1.text((1029, 790), str(v2bs), fill=(255, 255, 255))\n",
    "  v2bb=(v2b0+v2b1+v2b2+v2b3+v2bs)/5\n",
    "  d1.text((1100,780 ), str(v2bb), fill=(255, 255, 255))\n",
    "  result = result.save(img_pathdes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2123979,
     "status": "ok",
     "timestamp": 1656994657470,
     "user": {
      "displayName": "mahdi azmoodeh",
      "userId": "07920559924737018455"
     },
     "user_tz": -270
    },
    "id": "Gr-Jvcyz7B8c",
    "outputId": "cb2b8395-db57-4aa2-d6e5-61f343816c11"
   },
   "outputs": [],
   "source": [
    "#multigradcam for malignant\n",
    "import os\n",
    "from PIL import Image \n",
    "import PIL\n",
    "from PIL import Image, ImageDraw  \n",
    "root_src = 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\1\\\\test\\\\malignant'\n",
    "base_input_shapev1b0 = modelv1b0.input_shape[1:]\n",
    "base_input_shapev1b1 = modelv1b1.input_shape[1:]\n",
    "base_input_shapev1b2 = modelv1b2.input_shape[1:]\n",
    "base_input_shapev1b3 = modelv1b3.input_shape[1:]\n",
    "base_input_shapev1b4 = modelv1b4.input_shape[1:]\n",
    "base_input_shapev2b0 = modelv2b0.input_shape[1:]\n",
    "base_input_shapev2b1 = modelv2b1.input_shape[1:]\n",
    "base_input_shapev2b2 = modelv2b2.input_shape[1:]\n",
    "base_input_shapev2b3 = modelv2b3.input_shape[1:]\n",
    "base_input_shapev2bs = modelv2bS.input_shape[1:]\n",
    "\n",
    "layer_name = 'top_activation'\n",
    "files=[]\n",
    "files = os.listdir(root_src)\n",
    "for file in files:\n",
    "    #v1\n",
    "  img_path=os.path.join(root_src,file)\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b0[0], base_input_shapev1b0[1]))\n",
    "  camv1b0 = grad_cam(modelv1b0, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b0=modelv1b0.predict(x)\n",
    "  v1b0=v1b0[0][1]\n",
    "\n",
    "\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b1[0], base_input_shapev1b1[1]))\n",
    "  camv1b1 = grad_cam(modelv1b1, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b1=modelv1b1.predict(x)\n",
    "  v1b1=v1b1[0][1]\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b2[0], base_input_shapev1b2[1]))\n",
    "  camv1b2 = grad_cam(modelv1b2, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b2=modelv1b2.predict(x)\n",
    "  v1b2=v1b2[0][1]\n",
    "\n",
    "\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b3[0], base_input_shapev1b3[1]))\n",
    "  camv1b3 = grad_cam(modelv1b3, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b3=modelv1b3.predict(x)\n",
    "  v1b3=v1b3[0][1]\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev1b4[0], base_input_shapev1b4[1]))\n",
    "  camv1b4 = grad_cam(modelv1b4, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  v1b4=modelv1b4.predict(x)\n",
    "  v1b4=v1b4[0][1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  #v2  \n",
    "  img_path=os.path.join(root_src,file)\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2b0[0], base_input_shapev2b0[1]))\n",
    "  camv2b0 = grad_cam(modelv2b0, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2b0=modelv2b0.predict(x)\n",
    "  v2b0=v2b0[0][1]\n",
    "\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2b1[0], base_input_shapev2b1[1]))\n",
    "  camv2b1 = grad_cam(modelv2b1, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2b1=modelv2b1.predict(x)\n",
    "  v2b1=v2b1[0][1]\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2b2[0], base_input_shapev2b2[1]))\n",
    "  camv2b2 = grad_cam(modelv2b2, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2b2=modelv2b2.predict(x)\n",
    "  v2b2=v2b2[0][1]\n",
    "\n",
    "\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2b3[0], base_input_shapev2b3[1]))\n",
    "  camv2b3 = grad_cam(modelv2b3, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2b3=modelv2b3.predict(x)\n",
    "  v2b3=v2b3[0][1]\n",
    "\n",
    "  img_pil = tf.keras.preprocessing.image.load_img(img_path, target_size=(base_input_shapev2bs[0], base_input_shapev2bs[1]))\n",
    "  camv2bs = grad_cam(modelv2bS, img_pil, layer_name)\n",
    "  img_arr = tf.keras.preprocessing.image.img_to_array(img_pil)\n",
    "  x = img_arr[tf.newaxis]\n",
    "  x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "  v2bs=modelv2bS.predict(x)\n",
    "  v2bs=v2bs[0][1]\n",
    "####\n",
    "\n",
    "\n",
    "  img_pathdes=os.path.join('C:\\\\Users\\\\Administrator\\\\Desktop\\\\multigradcam\\\\malignant',file)\n",
    "  result=merge_images(camv1b0,camv1b1,camv1b2,camv1b3,camv1b4,camv2b0,camv2b1,camv2b2,camv2b3,camv2bs)\n",
    "  d1 = ImageDraw.Draw(result)\n",
    "  d1.text((5, 370), str(v1b0), fill=(255, 255, 255))\n",
    "  d1.text((229, 370), str(v1b1), fill=(255, 255, 255))\n",
    "  d1.text((469, 370), str(v1b2), fill=(255, 255, 255))\n",
    "  d1.text((729, 370), str(v1b3), fill=(255, 255, 255))\n",
    "  d1.text((1029, 390), str(v1b4), fill=(255, 255, 255))\n",
    "  v1bb=(v1b0+v1b1+v1b2+v1b3+v1b4)/5\n",
    "  d1.text((1100,380 ), str(v1bb), fill=(255, 255, 255))\n",
    "  \n",
    "    \n",
    "  d1.text((5, 770), str(v2b0), fill=(255, 255, 255))\n",
    "  d1.text((229, 770), str(v2b1), fill=(255, 255, 255))\n",
    "  d1.text((469, 770), str(v2b2), fill=(255, 255, 255))\n",
    "  d1.text((729, 770), str(v2b3), fill=(255, 255, 255))\n",
    "  d1.text((1029, 790), str(v2bs), fill=(255, 255, 255))\n",
    "  v2bb=(v2b0+v2b1+v2b2+v2b3+v2bs)/5\n",
    "  d1.text((1100,780 ), str(v2bb), fill=(255, 255, 255))\n",
    "  #result.show()\n",
    "  result = result.save(img_pathdes)\n",
    "#result = result.save(img_pathdes)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0CngdSA92bQMF7Ttzr4iq",
   "collapsed_sections": [],
   "name": "multigradcam.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
